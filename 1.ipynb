{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9U4Ecmdya0cO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "Rvp8Vm7_a3Ip"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')"
      ],
      "metadata": {
        "id": "A0Cx8PT6v06R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Unzip the audio files\n",
        "with zipfile.ZipFile('audio_files.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('audio_files')\n",
        "\n",
        "# Convert audio files to spectrograms\n",
        "def audio_to_spectrogram(file_path):\n",
        "    y, sr = librosa.load(file_path)\n",
        "    spect = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    spect = librosa.power_to_db(spect, ref=np.max)\n",
        "    return spect\n",
        "\n",
        "# Load audio files and labels\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(10):\n",
        "    folder = f'audio_files/{i}'\n",
        "    for file_name in os.listdir(folder):\n",
        "        if file_name.endswith('.wav'):\n",
        "            file_path = os.path.join(folder, file_name)\n",
        "            spectrogram = audio_to_spectrogram(file_path)\n",
        "            data.append(spectrogram)\n",
        "            labels.append(i)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Create a simple model for classification\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(data, labels, epochs=10)\n",
        "\n",
        "# Save the model\n",
        "model.save('audio_classifier_model.h5')\n"
      ],
      "metadata": {
        "id": "87wgn_WQda6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}